\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%######## APS360: Uncomment your submission name
\newcommand{\apsname}{Project Proposal}
%\newcommand{\apsname}{Progress Report}
%\newcommand{\apsname}{Final Report}

%######## APS360: Put your Group Number here
\newcommand{\gpnumber}{18}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}

%######## APS360: Put your project Title here
\title{Project Proposal}


%######## APS360: Put your names, student IDs and Emails here
\author{Shiyao Qian  \\
Student\# 1009309071\\
\texttt{shiyao.qian@mail.utoronto.ca} \\
\And
Zhengfei Yu  \\
Student\# 1008982978 \\
\texttt{barryzhengfei.yu@mail.utoronto.ca} \\
\And
Ashley Wang  \\
Student\# 1009020186 \\
\texttt{ashleyqi.wang@mail.utoronto.ca} \\
\And
Teresa Tu \\
Student\# 1008903144 \\
\texttt{teresatu.tu@mail.utoronto.ca} \\
\AND
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy

\begin{document}

\maketitle

\begin{abstract}
The area the group is interested in is fruit categorization. Fruit, as one of the major categories of food in people’s life, requires a self detection to provide convenience in production, transportation, and purchase. The team would use CNN as the approach to perform recognition of those objects with complex traits and databases. 

The input image of the fruit passes through the convolutional layer, pooling layer, and fully connected layer, finally outputting the class probability. The baseline model for comparison is a Support Vector Machine (SVM), which will be tested on the fruits dataset, potentially using techniques like partial fit to manage memory limitations. The project will utilize the processed Fruits-360 dataset. However, the classification tool could cause problems considering privacy problems and limitations of both the model itself and the training data.

As a team, we have decided thorough efficient communication and meeting plans together with emergency plans to keep every member updated and prepared. Also, detailed assigned tasks are listed for future reference.
 %\textbf{ First Course Tutorial} for a quick start
%######## APS360: Do not change the next line. This shows your Main body page count.
----Total Pages: \pageref{last_page}
\end{abstract}
\section{Introduction}
Classifying different types of fruit has important applications in the agriculture, retail, and food processing industries. Automation in these areas can increase productivity and reduce human errors, allowing large amounts of product to be processed efficiently. The topic of our project is to develop a fruit classification system using deep learning techniques to automatically identify fruit types based on images. This can have applications in quality control, inventory management, and automated checkout systems.

Convolutional Neural Networks (CNNs) in deep learning are a suitable approach for this project because they can perform pattern recognition in large datasets, learn complex features from the data, such as color gradients, textures, and shapes, and accurately distinguish between similar fruits.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{Figs/model_diagram.png}
\end{center}
\caption{CNN Architecture for Fruit Classification}
\label{figure1}
\end{figure}

Figure~\ref{figure1} shows the overall architecture of the fruit classification system using a CNN, which will be discussed in detail in section~\ref{sec:Architecture}. It begins with an input image of a fruit, then extracts features such as shapes and colors in the convolutional layer. Following this, the dimensionality of the data is reduced while preserving important features in the pooling layer. The processed data is then analyzed for classification by being passed to a fully connected layer. Finally, the system outputs class probabilities, and the fruit is identified based on the highest probability.

\section{Background \& Related Work}
\label{headings}

Several applications and technologies have been developed to 
assist with image recognition and plant identification. This
 section highlights five key works that relate to our project.


\subsection{Google Photos}

Google Photos includes a feature that allows users to search for 
visually similar images across the World Wide Web. The application 
finds matches based on characteristics such as color, shape, or 
texture of the image~\citep{nieuwenhuysen2018information}. The 
Google Research team developed a distributed computing infrastructure to train large-scale neural 
networks, utilizing 16,000 CPUs in their data centers. This setup 
enables the identification of a wide variety of images, including
 fruits, plants, animals, and human faces\citep{lee2020algorithmic}.

\subsection{PlantNet}

PlantNet is an application that can identify up to 21,920 species
 of plants. It organizes plant species under broad headings such as
  the flora of Western Europe, the USA, and other regions, as well 
  as categories like invasive plants and weeds. The app allows users
   to contribute by confirming plant species, essentially training 
   the system. However, the information it provides is limited to a
    photo and the Latin name, with no links to external resources 
    \citep{bilyk2020assessment}.

\subsection{PlantSnap}
Similar to PlantNet, PlantSnap can identify over 585,000 plant 
species. However, it too lacks links to additional information 
sources, offering only an image and the species’ Latin name \citep{bilyk2020assessment}.

\subsection{Seek by iNaturalist}
This application leverages the iNaturalist community's large 
dataset to identify species based on images. It is capable of 
identifying plants at different taxonomic levels, such as species, 
genus, and class. In a test of five popular plant identification
apps, Seek correctly identified 85\% of images within the top five 
suggestions, with 69\% accuracy on the first suggestion \citep{inaturalist_taxa}\citep{hart2023assessing}.

\subsection{GitHub Fruit Classifier}
A program available on GitHub trained a model to classify 40 types 
of fruits, achieving an accuracy of 92.47\%. The model was 
developed using TensorFlow, making it closely related to our 
project in terms of the underlying technology and scope \citep{aparande_fruit_classification}.


\section{Data Processing}
For our project on plant and fruit identification, we will primarily utilize the Fruits-360 dataset, which consists of a vast collection of images featuring various fruits, vegetables, and nuts. This dataset includes 94,110 images scaled to 100x100 pixels, providing a consistent size that facilitates efficient processing. The dataset is well-structured, comprising 70,491 images for training and 23,619 images for testing, categorized into 141 distinct classes of fruits and vegetables.~\citep{moltean_fruits_360}

To enhance the quality of our dataset, we will implement several data processing steps, including collection, cleaning, and formatting. Although the Fruits-360 dataset is an established resource, we will conduct additional work to ensure that the data is optimized for our specific model requirements.

Data Cleaning: The first phase involves thorough cleaning to eliminate any discrepancies that could hinder model performance.
Removing Extra Data: Remove Images related to vegetables and nuts which are not included in our scope.
Removing Corrupted Images: We will systematically check for corrupted or unreadable files by attempting to load each image and catching any errors that arise. Any image that fails to load will be flagged and removed.
Removing Duplicates: To prevent duplicates from skewing our training process, we will employ hash functions to identify and eliminate identical images, enhancing the dataset's diversity.
Checking Labels: Ensuring the accuracy of labels is critical for supervised learning. We will manually verify a sample of labels and automate the process for the entire dataset using scripts. This will help catch and correct any inconsistencies.

Image Preprocessing (for Fruit Images): After cleaning, we will preprocess the images to prepare them for neural network input.
Resizing: All images will be resized to a consistent dimension, typically 224x224 pixels or 128x128 pixels. This standardization ensures that the model can effectively process the inputs.
Data Splitting: We will partition the dataset into training and test sets to evaluate the model's performance accurately.
Train-Test Split: The dataset will be divided into a training set comprising 80\% of the images and a test set comprising the remaining 20\%. This split allows us to train the model on one portion while reserving another for testing, preventing overfitting.
Final Formatting: The last step involves ensuring consistent formatting for the dataset.
Ensuring Consistency: We will maintain uniformity in data types across the dataset, with images represented as floating-point values and labels as integers. This consistency ensures efficient processing by the model.


\section{Architecture}
\label{sec:Architecture}
For this project, we will employ a CNN as our primary model architecture, leveraging its proven effectiveness in image recognition tasks. CNNs are particularly adept at identifying hierarchical patterns in spatial data, which makes them ideal for classifying images of fruits based on visual features. A visualisation of this structure is shown above in Figure~\ref{figure1}. The CNN architecture for this project will be composed of five main components:

Input Layer: This layer will accept color images of fruits, each with a resolution of 100x100 pixels. The input images will be standardized to ensure consistent sizing and color representation across all training and testing examples.

Convolutional Layers: Multiple convolutional layers will be used to extract various features from the images. These layers will apply a series of learnable filters to the input, each producing a feature map that emphasizes certain aspects of the image. We will experiment with different combinations of filters to optimize performance.

Pooling Layers: Following convolutional layers, pooling layers will reduce the spatial dimensions of the feature maps, thus decreasing the computational complexity and the number of parameters in the network. This consolidation of information helps to prevent overfitting on feature representations and increase robustness against small variations of them. We plan to use max pooling for its effectiveness in capturing the most salient features.

Fully Connected Layers: After feature extraction and consolidation, one or more fully connected layers will follow to interpret the feature data and classify input image into a fruit category. Each neuron in these layers will be connected to all activations from the previous layer, thus enabling the network to make decisions based on the global understanding of the image features.

\section{Baseline Model}
The baseline model that we will compare our neural networks against is SVM. SVM typically identify images by separating classes with hyperplanes, which is an efficient and relatively easier method. Therefore, it can provide us with an insight of how far a simple machine learning model can go in our task and help us set an expectation on our final model. We plan to implement this model using the sklearn library~\citep{sklearn_api} and test its performance on the processed Fruits-360 dataset. As the dataset contains a total of 94110 samples~\citep{moltean_fruits_360}, certain tricks partial fit may be needed when training the SVM to ensure that the model does not exhaust the memory resources available. 

\section{Ethical Considerations}
The possible risks could be privacy risk and threat to the labour market. For privacy risks, the photos the users upload may contain other backgrounds like their kitchen or superstores that may violate others’ privacy. Also, the fully developed fruit detection program may replace workers in the superstores or grocery stores, which may cause labour problems.

The CNN model is limited in some aspects. It requires a large number of labelled databases, which could be expensive and time-consuming. Also, the CNN model could have varying performance based on image type and may face challenges of overfitting, exploding gradient, and class imbalance~\cite{GeeksforGeeks_2021, deep_cnn_review_2017}.

In the case of training data, there are different categories of fruits and we need to cover as much as we can to be able to identify those fruits. There are also subcategories of each fruit, and if we could also include that, the result would be more detailed. Also, the same fruit may grow in different shapes or appearance in different places. We need to also account for that to ensure result accuracy.

\section{Project Plan}
We decided to have a regular meeting on Tuesday, 19:00, at the SF library on campus to keep updated with the current progress, discuss problems met, and modify plans on future tasks based on those. Besides these regular meetings, we could also communicate through group chat and each member is expected to reply within 10 hours to ensure efficient communication. A remote meeting on zoom will be added one day before the deadline for final checking on the work to be uploaded. Also, since we are using Google Docs and Google Colab for all the collaborated work, commenting and editing functions embedded could also perform its role in idea sharing and discussion. Using the shared Google Drive, we could follow the assigned tasks list in Table 2 and finish our own parts before the deadline, which allows the next person to start the next progress. We will do version control of coding using google colab’s version history. Overwriting of code can be avoided with detailed discussion and task assignment before coding.  If necessary, we may divide up the code and save one copy of it for each person on google drive before merging the code together.
\clearpage
\begin{table}[hp]
\caption{Current Project Tasks and Deadlines}
\label{sample-table}
\vspace{0.5cm}
\begin{tabular}{p{0.75in}p{1.25in}p{2.25in}p{1.25in}}
\multicolumn{1}{c}{\bf NAME}  &\multicolumn{1}{c}{\bf TASK} &\multicolumn{1}{c}{\bf DESCRIPTION} &\multicolumn{1}{c}{\bf INTERNAL DEADLINE}
\\ \hline \\
Ashley Wang &Introduction  &describe the project topic and objective &Oct 2, 2024 \\
Ashley Wang &Illustration  &illustrates the overall model and summarizes the model core  &Oct 2, 2024\\
Zhengfei Yu   &Background \& related work   &explored various image recognition and plant identification technologies, highlighting their features, performance, and relevance to the project    &Oct 2, 2024\\
Zhengfei Yu   &Data processing  &Describe the process of utilizing the Fruits-360 dataset, detailing the data cleaning steps, followed by image preprocessing tasks and ensuring consistent data formatting to optimize it for model training. &Oct 2, 2024\\
Shiyao Qian  &Architecture  &Describe in detail the actual neural network structure that is going to be used as the model &Oct 2, 2024\\
Shiyao Qian  &Baseline model  &Choose the model as baseline for comparison and state the plan its implementation  &Oct 2, 2024\\
Teresa Tu  &Ethical consideration  &explore and research the possible ethical risks of the project &Oct 2, 2024\\
Teresa Tu  &Risk register  &Discuss, evaluate and plan for the possible risks that could affect the completion of the project  &Oct 2, 2024\\
\end{tabular}
\end{table}

\begin{table}[hp]
\caption{Future Project Tasks and Deadlines}
\label{project-tasks}
\begin{center}
\begin{tabular}{p{1.25in} p{2.5in} p{1.25in}}
\multicolumn{1}{c}{\bf NAME} & \multicolumn{1}{c}{\bf FUTURE TASKS FOR CODING} & \multicolumn{1}{c}{\bf INTERNAL DEADLINE} \\ \hline \\
Zhengfei Yu & 
\begin{tabular}[c]{@{}l@{}} 
Collecting Data: \\ 
- Finding a reliable dataset where each image\\is already associated with a label\\corresponding to the fruit type. \\ 
- Taking pictures of real fruit for real-world\\scenarios. \\ 
- Organizing the pictures in the proper fruit\\class folder. 
Each subfolder contains images\\of the respective fruit. \\ \\
Processing Data: \\ 
- Resizing images to a fixed size (e.g., 100x\\100 pixels) for consistency. \\ 
- Scaling pixel values from the default\\range [0, 255] to [0, 1]. \\ 
- Splitting the dataset into a training set (60\%),\\validation set (20\%), and testing set (20\%).
\end{tabular} & Oct 13, 2024 \\ \hline \\
Shiyao Qian & 
\begin{tabular}[c]{@{}l@{}} 
Building the CNN Model: \\ 
- Input Layer: Define the input shape\\(e.g., 100x100x3 for RGB images). \\ 
- Convolutional Layers: Add layers to extract\\ features. \\ 
- Pooling Layers: Use max pooling to reduce\\dimensionality. \\ 
- Dropout: Add layers to prevent overfitting. \\ 
- Fully Connected Layers: Add dense layers to\\classify fruit. \\ 
- Output Layer: Final dense layer with softmax\\activation for multi-class classification. \\ \\
Compiling the Model: \\ 
- Choose an optimizer (e.g., Adam). \\ 
- Define the loss function (e.g., categorical\\cross-entropy). \\ 
- Specify performance metrics (e.g., accuracy).
\end{tabular} & Oct 20, 2024 \\ \hline \\
Ashley Wang & 
\begin{tabular}[c]{@{}l@{}} 
Training the Model: \\ 
- Use the training data to fit the model. \\ 
- Set parameters such as batch size. \\ 
- Validate accuracy and error. \\ \\
Evaluating the Model: \\ 
- Evaluate the model on the validation set. \\ 
- Understand the misclassified fruit type.
\end{tabular} & Oct 27, 2024 \\ \hline \\
Teresa Tu & 
\begin{tabular}[c]{@{}l@{}} 
Testing the Model: \\ 
- Perform the model using separate test data. \\ 
- Calculate the final accuracy metrics. \\ \\
Model Tuning: \\ 
- Change parameters like learning rate, number\\of layers, etc.
\end{tabular} & Nov 03, 2024 \\ 
\end{tabular}
\end{center}
\end{table}


\raggedright
\sloppy
\clearpage
\label{last_page}

\bibliography{reference.bib}
\bibliographystyle{iclr2022_conference}



\end{document}
